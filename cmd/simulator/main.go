package main

import (
	"bytes"
	"encoding/json"
	"fmt"
	"log"
	"net/http"
	"time"
)

// çˆ¬è™«æ¨¡æ‹Ÿå™¨é…ç½®
type CrawlerConfig struct {
	BaseURL    string `json:"base_url"`
	Username   string `json:"username"`
	Password   string `json:"password"`
	Interval   int    `json:"interval"`    // çˆ¬å–é—´éš”ï¼ˆç§’ï¼‰
	MaxRetries int    `json:"max_retries"` // æœ€å¤§é‡è¯•æ¬¡æ•°
}

// çˆ¬è™«æ¨¡æ‹Ÿå™¨
type CrawlerSimulator struct {
	config     CrawlerConfig
	authToken  string
	httpClient *http.Client
}

// åˆ›å»ºæ–°çš„çˆ¬è™«æ¨¡æ‹Ÿå™¨
func NewCrawlerSimulator(config CrawlerConfig) *CrawlerSimulator {
	return &CrawlerSimulator{
		config: config,
		httpClient: &http.Client{
			Timeout: 30 * time.Second,
		},
	}
}

// ç™»å½•è·å–è®¤è¯ä»¤ç‰Œ
func (c *CrawlerSimulator) login() error {
	loginData := map[string]string{
		"username": c.config.Username,
		"password": c.config.Password,
	}

	jsonData, err := json.Marshal(loginData)
	if err != nil {
		return fmt.Errorf("åºåˆ—åŒ–ç™»å½•æ•°æ®å¤±è´¥: %v", err)
	}

	resp, err := c.httpClient.Post(
		c.config.BaseURL+"/api/login",
		"application/json",
		bytes.NewBuffer(jsonData),
	)
	if err != nil {
		return fmt.Errorf("ç™»å½•è¯·æ±‚å¤±è´¥: %v", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return fmt.Errorf("ç™»å½•å¤±è´¥ï¼ŒçŠ¶æ€ç : %d", resp.StatusCode)
	}

	var result struct {
		Success bool `json:"success"`
		Data    struct {
			Token string `json:"token"`
		} `json:"data"`
		Message string `json:"message"`
	}

	if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
		return fmt.Errorf("è§£æç™»å½•å“åº”å¤±è´¥: %v", err)
	}

	if !result.Success {
		return fmt.Errorf("ç™»å½•å¤±è´¥: %s", result.Message)
	}

	c.authToken = result.Data.Token
	log.Printf("âœ… ç™»å½•æˆåŠŸï¼Œè·å–åˆ°è®¤è¯ä»¤ç‰Œ")
	return nil
}

// è·å–çˆ¬è™«ä»»åŠ¡
func (c *CrawlerSimulator) fetchTasks() (*FetchTask, error) {
	req, err := http.NewRequest("GET", c.config.BaseURL+"/fetch", nil)
	if err != nil {
		return nil, fmt.Errorf("åˆ›å»ºè¯·æ±‚å¤±è´¥: %v", err)
	}

	req.Header.Set("Authorization", "Bearer "+c.authToken)

	resp, err := c.httpClient.Do(req)
	if err != nil {
		return nil, fmt.Errorf("è·å–ä»»åŠ¡å¤±è´¥: %v", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return nil, fmt.Errorf("è·å–ä»»åŠ¡å¤±è´¥ï¼ŒçŠ¶æ€ç : %d", resp.StatusCode)
	}

	var result struct {
		Success bool      `json:"success"`
		Data    FetchTask `json:"data"`
		Message string    `json:"message"`
	}

	if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
		return nil, fmt.Errorf("è§£æä»»åŠ¡å“åº”å¤±è´¥: %v", err)
	}

	if !result.Success {
		return nil, fmt.Errorf("è·å–ä»»åŠ¡å¤±è´¥: %s", result.Message)
	}

	log.Printf("ğŸ“‹ è·å–åˆ° %d ä¸ªçˆ¬è™«ä»»åŠ¡", len(result.Data.URLs))
	return &result.Data, nil
}

// æ¨¡æ‹Ÿçˆ¬å–æ•°æ®
func (c *CrawlerSimulator) crawlData(urls []string) []FetchResult {
	var results []FetchResult

	for _, url := range urls {
		// æ¨¡æ‹Ÿçˆ¬å–å»¶è¿Ÿ
		time.Sleep(500 * time.Millisecond)

		// æ¨¡æ‹Ÿä¸åŒçš„çˆ¬å–ç»“æœ
		result := c.simulateCrawlResult(url)
		results = append(results, result)

		log.Printf("ğŸ•·ï¸ æ¨¡æ‹Ÿçˆ¬å–: %s -> %s", url, result.Name)
	}

	return results
}

// æ¨¡æ‹Ÿçˆ¬å–ç»“æœ
func (c *CrawlerSimulator) simulateCrawlResult(url string) FetchResult {
	// æ ¹æ® URL ç”Ÿæˆä¸åŒçš„æ¨¡æ‹Ÿæ•°æ®
	episodeCount := len(url)%10 + 1 // 1-10 é›†
	seasonCount := len(url)%3 + 1   // 1-3 å­£

	var series []string
	for season := 1; season <= seasonCount; season++ {
		for episode := 1; episode <= episodeCount; episode++ {
			series = append(series, fmt.Sprintf("S%02dE%02d", season, episode))
		}
	}

	// éšæœºé€‰æ‹©ä¸€äº›é›†æ•°ä½œä¸º"æ–°å‘ç°"
	newEpisodes := len(series)%3 + 1
	if newEpisodes > len(series) {
		newEpisodes = len(series)
	}

	// æ¨¡æ‹Ÿå‘ç°æ–°é›†æ•°
	discoveredSeries := series[:newEpisodes]
	currentEpisode := discoveredSeries[len(discoveredSeries)-1]

	return FetchResult{
		Name:   fmt.Sprintf("æ¨¡æ‹Ÿå‰§é›†-%s", url[len(url)-8:]), // å– URL å8ä½ä½œä¸ºåç§°
		Update: currentEpisode,
		URL:    url,
		Series: discoveredSeries,
	}
}

// ä¸ŠæŠ¥çˆ¬å–ç»“æœ
func (c *CrawlerSimulator) reportResults(tasks []string, results []FetchResult) error {
	callbackData := FetchCallback{
		Tasks:   tasks,
		Results: results,
		Status:  0,
		Message: "success",
	}

	jsonData, err := json.Marshal(callbackData)
	if err != nil {
		return fmt.Errorf("åºåˆ—åŒ–å›è°ƒæ•°æ®å¤±è´¥: %v", err)
	}

	req, err := http.NewRequest("POST", c.config.BaseURL+"/fetch", bytes.NewBuffer(jsonData))
	if err != nil {
		return fmt.Errorf("åˆ›å»ºå›è°ƒè¯·æ±‚å¤±è´¥: %v", err)
	}

	req.Header.Set("Content-Type", "application/json")
	req.Header.Set("Authorization", "Bearer "+c.authToken)

	resp, err := c.httpClient.Do(req)
	if err != nil {
		return fmt.Errorf("ä¸ŠæŠ¥ç»“æœå¤±è´¥: %v", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != http.StatusOK {
		return fmt.Errorf("ä¸ŠæŠ¥ç»“æœå¤±è´¥ï¼ŒçŠ¶æ€ç : %d", resp.StatusCode)
	}

	var result struct {
		Success bool   `json:"success"`
		Message string `json:"message"`
	}

	if err := json.NewDecoder(resp.Body).Decode(&result); err != nil {
		return fmt.Errorf("è§£æå›è°ƒå“åº”å¤±è´¥: %v", err)
	}

	if !result.Success {
		return fmt.Errorf("ä¸ŠæŠ¥ç»“æœå¤±è´¥: %s", result.Message)
	}

	log.Printf("ğŸ“¤ æˆåŠŸä¸ŠæŠ¥ %d ä¸ªçˆ¬å–ç»“æœ", len(results))
	return nil
}

// è¿è¡Œçˆ¬è™«æ¨¡æ‹Ÿå™¨
func (c *CrawlerSimulator) Run() error {
	log.Printf("ğŸš€ å¯åŠ¨çˆ¬è™«æ¨¡æ‹Ÿå™¨")
	log.Printf("ğŸ“¡ ç›®æ ‡æœåŠ¡å™¨: %s", c.config.BaseURL)
	log.Printf("ğŸ‘¤ ç”¨æˆ·å: %s", c.config.Username)
	log.Printf("â° çˆ¬å–é—´éš”: %d ç§’", c.config.Interval)

	// é¦–æ¬¡ç™»å½•
	if err := c.login(); err != nil {
		return fmt.Errorf("åˆå§‹ç™»å½•å¤±è´¥: %v", err)
	}

	// å¾ªç¯çˆ¬å–
	for {
		log.Printf("\nğŸ”„ å¼€å§‹æ–°ä¸€è½®çˆ¬å–...")

		// è·å–ä»»åŠ¡
		task, err := c.fetchTasks()
		if err != nil {
			log.Printf("âŒ è·å–ä»»åŠ¡å¤±è´¥: %v", err)

			// å°è¯•é‡æ–°ç™»å½•
			if err := c.login(); err != nil {
				log.Printf("âŒ é‡æ–°ç™»å½•å¤±è´¥: %v", err)
			}

			time.Sleep(time.Duration(c.config.Interval) * time.Second)
			continue
		}

		if len(task.URLs) == 0 {
			log.Printf("ğŸ“­ æ²¡æœ‰éœ€è¦çˆ¬å–çš„ä»»åŠ¡")
			time.Sleep(time.Duration(c.config.Interval) * time.Second)
			continue
		}

		// æ¨¡æ‹Ÿçˆ¬å–æ•°æ®
		results := c.crawlData(task.URLs)

		// ä¸ŠæŠ¥ç»“æœ
		if err := c.reportResults(task.URLs, results); err != nil {
			log.Printf("âŒ ä¸ŠæŠ¥ç»“æœå¤±è´¥: %v", err)
		}

		log.Printf("âœ… æœ¬è½®çˆ¬å–å®Œæˆï¼Œç­‰å¾… %d ç§’åç»§ç»­...", c.config.Interval)
		time.Sleep(time.Duration(c.config.Interval) * time.Second)
	}
}

// ä¸»å‡½æ•° - çˆ¬è™«æ¨¡æ‹Ÿå™¨å…¥å£
func main() {
	// é…ç½®çˆ¬è™«æ¨¡æ‹Ÿå™¨
	config := CrawlerConfig{
		BaseURL:    "http://localhost:8080",
		Username:   "admin",
		Password:   "admin123",
		Interval:   30, // 30ç§’çˆ¬å–ä¸€æ¬¡
		MaxRetries: 3,
	}

	// åˆ›å»ºçˆ¬è™«æ¨¡æ‹Ÿå™¨
	crawler := NewCrawlerSimulator(config)

	// è¿è¡Œçˆ¬è™«
	if err := crawler.Run(); err != nil {
		log.Fatalf("çˆ¬è™«è¿è¡Œå¤±è´¥: %v", err)
	}
}

// æ•°æ®ç»“æ„å®šä¹‰ï¼ˆä¸ä¸»ç¨‹åºä¿æŒä¸€è‡´ï¼‰
type FetchTask struct {
	URLs        []string `json:"tasks"`
	CallbackURL string   `json:"callback_url"`
}

type FetchResult struct {
	Name   string   `json:"name"`
	Update string   `json:"update"`
	URL    string   `json:"url"`
	Series []string `json:"series"`
}

type FetchCallback struct {
	Tasks   []string      `json:"tasks"`
	Results []FetchResult `json:"results"`
	Status  int           `json:"status"`
	Message string        `json:"message"`
}
